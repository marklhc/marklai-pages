---
title: "Multilevel Models for Experimental Data"
output:
  html_document:
    df_print: paged
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = ">#")
```

## Load Packages and Import Data

```{r load-pkg, message=FALSE}
# To install a package, run the following ONCE (and only once on your computer)
# install.packages("psych")  
library(here)  # makes reading data more consistent
library(tidyverse)  # for data manipulation and plotting
library(haven)  # for importing SPSS/SAS/Stata data
library(lme4)  # for multilevel analysis
library(lmerTest)  # for testing coefficients
library(lattice)  # for dotplot (working with lme4)
library(sjPlot)  # for plotting effects
library(broom.mixed)  # for summarizing results
library(modelsummary)  # for making tables
# Add the following so that the LOO will be included in the msummary table
glance_custom.brmsfit <- function(x) {
  broom.mixed::glance(x, looic = TRUE)
}
theme_set(theme_bw())  # Theme; just my personal preference
```

Cluster-randomized trial: https://www.sciencedirect.com/science/article/abs/pii/S0022103117300860

```{r driving_dat}
# Data example of Hoffman & Atchley (2001)
# Download from the Internet, unzip, and read in
zip_path <- here("data_files", "MLM_for_Exp_Appendices.zip")
if (!file.exists(zip_path)) {
  download.file(
    "http://www.lesahoffman.com/Research/MLM_for_Exp_Appendices.zip", 
    zip_path)
}
driving_dat <- read_sav(unz(zip_path, "MLM_for_Exp_Appendices/Ex1.sav"))
# Convert `sex` and `oldage` to factor
# Note: also convert id and Item to factor (just for plotting)
driving_dat <- driving_dat %>% 
  mutate(sex = as_factor(sex), 
         oldage = factor(oldage, levels = c(0, 1), 
                         labels = c("Below Age 40", "Over Age 40")), 
         id = factor(id), 
         Item = factor(Item))
driving_dat
```

With SPSS data, you can view the variable labels by 

```{r show-labels}
# Show the variable labels
map(driving_dat, attr, "label")
```

## Wide and Long Format

The data we used here is in what is called a *long format*, where each row corresponds to a unique observation, and is required for MLM. More commonly, however, you may have data in a *wide format*, where each row records multiple observations for each person, as shown below

```{r driving_wide, include=FALSE}
driving_wide <- pivot_wider(driving_dat, id_cols = c(id, sex, age), 
                            names_from = NAME, values_from = rt_sec)
```

```{r print-driving_wide}
driving_wide
```

As can be seen above, `rt_sec1` to `rt_sec80` are the responses to the 51 items. If you have like the above, you need to convert it to a long format. In R, this can be achieved using the `pivot_long()` function, as part of `tidyverse` (in the `tidyr` package):

```{r long-to-wide}
driving_wide %>% 
  pivot_longer(
    cols = rt_sec1:rt_sec80,  # specify the columns of repeated measures
    names_to = "Item",  # name of the new column to create to indicate item id
    names_prefix = "rt_sec",  # remove "rt_sec" from the item ID column
    values_to = "rt_sec",  # name of new column containing the response
  )
```

## Descriptive Statistics

### Missing Data Rate for Response Time:

```{r missing-data}
driving_dat %>% 
  group_by(id) %>% 
  summarise(n_missing = sum(is.na(rt_sec))) %>% 
  ggplot(aes(x = n_missing)) + 
  geom_bar()
```

Note that only about 80 people have no missing data

### Plotting

Here I will show you the use of `GGally::

```{r pairs, warning=FALSE}
psych::pairs.panels(driving_dat %>%
                      # Select six variables
                      select(sex, age, rt_sec, meaning, salience, lg_rt), 
                    ellipses = FALSE, cex = 0.2, cex.cor = 1)
```

Note the nonnormality in response time. There doesn't appear to be much gender
differences. 

Below is a plot between response time against age:

Left: original response time; Right: Natural log transformation

```{r plot-rt-age}
p1 <- driving_dat %>% 
  ggplot(aes(x = age, y = rt_sec)) +
  geom_jitter(width = 0.5, height = 0, alpha = 0.5) + 
  geom_smooth()
p2 <- driving_dat %>% 
  ggplot(aes(x = age, y = lg_rt)) +
  geom_jitter(width = 0.5, height = 0, alpha = 0.5) + 
  geom_smooth()
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

## Cross-Classified Random Effect Analysis

```{r network-graph, echo=FALSE}
DiagrammeR::grViz("
digraph boxes_and_circles {
  graph [layout = neato, overlap = true, fontsize = 30]

  node [penwidth = 0, fontname = 'Helvetica']
  # Person
  1 [pos = '-2,1!', label='Person 1']
  2 [pos = '-1,1!', label='Person 2'] 
  3 [pos = '0,1!', label='Person 3']
  4 [pos = '1,1!', label='Person 4']
  5 [pos = '2,1!', label='Person 5']
  # Repeated measures
  y1 [pos = '-2.33,0!']
  y2 [pos = '-2,0!']
  y3 [pos = '-1.67,0!']
  y4 [pos = '-1.33,0!']
  y5 [pos = '-1,0!']
  y6 [pos = '-0.67,0!']
  y7 [pos = '-0.33,0!']
  y8 [pos = '0,0!']
  y9 [pos = '0.33,0!']
  y10 [pos = '0.67,0!']
  y11 [pos = '1,0!']
  y12 [pos = '1.33,0!']
  y13 [pos = '1.67,0!']
  y14 [pos = '2,0!']
  y15 [pos = '2.33,0!']
  
  # Item
  i1 [pos = '-1.5,-1!', label='Item 1']
  i2 [pos = '-0,-1!', label='Item 2']
  i3 [pos = '1.5,-1!', label='Item 3']

  # edges
  edge [dir = 'none']
  1 -> {y1; y2; y3}
  2 -> {y4; y5; y6}
  3 -> {y7; y8; y9}
  4 -> {y10; y11; y12}
  5 -> {y13; y14; y15}
  {y1 y4 y7 y10 y13} -> i1
  {y2 y5 y8 y11 y14} -> i2
  {y3 y6 y9 y12 y15} -> i3
}
")
```

## Intraclass Correlations and Design Effects

```{r icc-m0}
m0 <- lmer(lg_rt ~ (1 | id) + (1 | Item), data = driving_dat)
vc_m0 <- as.data.frame(VarCorr(m0))
# ICC/Deff (person; cluster size = 51)
icc_person <- vc_m0$vcov[1] / sum(vc_m0$vcov)
c("ICC(person)" = icc_person, 
  "Deff(person)" = 1 + (51 - 1) * icc_person)
# ICC (item; cluster size = 153)
icc_item <- vc_m0$vcov[2] / sum(vc_m0$vcov)
c("ICC(item)" = icc_item, 
  "Deff(item)" = 1 + (153 - 1) * icc_item)
# ICC (person + item)
c("ICC(person + item)" = sum(vc_m0$vcov[1:2]) / sum(vc_m0$vcov))
```

### Visualizing person-level and item-level variances

```{r var-across-person-item}
set.seed(2124)
# Variation across persons
random_ids <- sample(unique(driving_dat$id), size = 10)
driving_dat %>%
    filter(id %in% random_ids) %>%  # select only 10 persons
    ggplot(aes(x = id, y = lg_rt)) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.3) +
    # Add person means
    stat_summary(
      fun = "mean",
      geom = "point",
      col = "red",
      shape = 17,  # use triangles
      size = 4  # make them larger
    ) 
# Variation across items
random_items <- sample(unique(driving_dat$Item), size = 10)
driving_dat %>%
    filter(Item %in% random_items) %>%  # select only 10 persons
    ggplot(aes(x = factor(Item), y = lg_rt)) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.3) +
    # Add person means
    stat_summary(
      fun = "mean",
      geom = "point",
      col = "red",
      shape = 17,  # use triangles
      size = 4  # make them larger
    ) 
```


Account for shared variance of item:

- Now, it can be seen that `c_mean` and `c_sal` are item-level variables. The model is complex, but one thing that we don't need to worry is that if the experimental design is balanced (i.e., every item was administered to every person), we don't need to worry about cluster-means and cluster-mean centering. In this case, `c_mean` and `c_sal` are purely item-level variables with no person-level variance. You can verify this:

```{r icc-c_mean}
lmer(c_mean ~ (1 | id), data = driving_dat)
```

This, however, does not apply to unbalanced data, in which case cluster-means will still be needed. 

## Full Model

### Equations

Repeated-Measure level (Lv 1):
$$\text{lg_rt}_{i(j, k)} = \beta_{0(j, k)} + e_{ijk}$$
Between-cell (Person $\times$ Item) level (Lv 2):
$$\beta_{0(j, k)} = \gamma_{00} + \beta_{1j} \text{meaning}_{ik} + \beta_{2j} \text{salience}_{ik} + \beta_{3j} \text{meaning}_{ik} \times \text{salience}_{ik} + \beta_{4k} \text{oldage}_{ij} + u_{0j} + v_{0k}$$
Person level (Lv 2a) random slopes
$$
\begin{aligned}
  \beta_{1j} = \gamma_{10} + \gamma_{11} \text{oldage}_{ij} + u_{1j} \\
  \beta_{2j} = \gamma_{20} + \gamma_{21} \text{oldage}_{ij} + u_{2j} \\
  \beta_{3j} = \gamma_{30} + \gamma_{31} \text{oldage}_{ij} + u_{3j} \\
\end{aligned}
$$
Item level (Lv2b) random slopes
$$\beta_{4k} = \gamma_{40} + v_{4k}$$
Combined equations
$$
\begin{aligned}
  \text{lg_rt}_{i(j,k)} & = \gamma_{00} \\ 
                        & + \gamma_{10} \text{meaning}_{ik} + \gamma_{20} \text{salience}_{ik} + \gamma_{30} \text{meaning}_{ik} \times \text{salience}_{ik} + \gamma_{40} \text{oldage}_{ij} \\
                        & + \gamma_{11} \text{meaning}_{ik} \times \text{oldage}_{ij} + \gamma_{21} \text{salience}_{ik} \times \text{oldage}_{ij} + \gamma_{31} \text{meaning}_{ik} \times \times \text{oldage}_{ij} \times \text{oldage}_{ij} + \\
                        & + u_{0j} + u_{1j} \text{meaning}_{ik} + u_{2j} \text{salience}_{ik} + u_{3j} \text{meaning}_{ik} \times \text{salience}_{ik} \\
                        & + v_{0k} + v_{4k} \text{oldage}_{ij} \\
                        & + e_{ijk}
\end{aligned}
$$

### Testing random slopes

The random slopes will be tested one by one

```{r test-random-slopes}
# First, no random slopes
m1 <- lmer(lg_rt ~ c_mean * c_sal * oldage + (1 | id) + (1 | Item), 
           data = driving_dat)
# Then test random slopes one by one
# Random slopes of oldage (person-level) across items
m1_rs1 <- lmer(lg_rt ~ c_mean * c_sal * oldage + (1 | id) + (oldage | Item), 
               data = driving_dat)
# Test
ranova(m1_rs1)  # statistically significant, indicating varying slopes of 
                # oldage
# Random slopes of c_mean (item-level) across persons
m1_rs2 <- lmer(lg_rt ~ c_mean * c_sal * oldage + (c_mean:c_sal | id) + 
                 (1 | Item), 
               data = driving_dat)
# Test
ranova(m1_rs2)  # not statistically significant
# Random slopes of c_mean (item-level) across persons
m1_rs3 <- lmer(lg_rt ~ c_mean * c_sal * oldage + (c_mean | id) + (1 | Item), 
               data = driving_dat)
# Test
ranova(m1_rs3)  # not statistically significant
# Random slopes of c_sal (item-level) across persons
m1_rs4 <- lmer(lg_rt ~ c_mean * c_sal * oldage + (c_sal | id) + (1 | Item), 
               data = driving_dat)
# Test
ranova(m1_rs4)  # statistically significant
```

```{r explore-models}
# So the final model should include random slopes of oldage (person-level)
# across items and c_sal across persons
m1_rs <- lmer(lg_rt ~ c_mean * c_sal * oldage + (c_sal | id) + (oldage | Item), 
              data = driving_dat)
# LRT for three-way interaction
confint(m1_rs, parm = "c_mean:c_sal:oldageOver Age 40")
# Dropping non-sig 3-way interaction
m2_rs <- lmer(lg_rt ~ (c_mean + c_sal + oldage)^2 + (c_sal | id) + 
                (oldage | Item), 
              data = driving_dat)
# Compare model with and without two-way interactions
m3_rs <- lmer(lg_rt ~ c_mean + c_sal + oldage + (c_sal | id) + 
                (oldage | Item), 
              data = driving_dat)
anova(m2_rs, m3_rs)  # not significant
# So we keep the additive model (i.e., no interaction)
```

#### Plot the 3-way interaction

Even though the 3-way interaction was not statistically significant, given that it was part of the prespecified hypothesis, let's plot it

```{r plot-m1_rs}
plot_model(m1_rs, type = "int", 
           show.data = TRUE, jitter = 0.1, 
           dot.alpha = 0.5, dot.size = 0.1)
```

#### Plot the marginal age effect

```{r plot-m3_rs}
# plot_model() function is from the `sjPlot` package
p1 <- plot_model(m3_rs, type = "pred", terms = "c_mean", 
                 show.data = TRUE, jitter = 0.1, 
                 dot.alpha = 0.5, dot.size = 0.1)
# Plot random slopes
p2 <- plot_model(m3_rs, type = "pred", 
                 terms = c("c_sal", "id [1:274]"), 
                 pred.type = "re", show.legend = FALSE, 
                 colors = "black", alpha = 0.1, 
                 show.data = TRUE, jitter = 0.1, 
                 dot.alpha = 0.5, dot.size = 0.1)
# Plot first 10 items
p3 <- plot_model(m3_rs, type = "pred", 
           terms = c("Item [1:10]", "oldage"), 
           pred.type = "re") + 
  theme(legend.position = "top")
gridExtra::grid.arrange(p1, p2, p3, ncol = 2)
```

## Effect Size

There are multiple ways to standardize. For me, the goal of standardization is usually to put the effects in a unit that represents the natural standard deviation in the population. In this case, we think about the natural variation in reaction time across persons, without the experimental manipulation, which should be the between-person variance component (stable individual differences, $\tau_{u_0}^2$) plus the random error ($\sigma^2$) from the unconditional model. So we'll define Cohen's $d$ as
$$d = \frac{\hat \gamma}{\sqrt{\tau_{u_0}^2 + \sigma^2}},$$
where $\hat \gamma$ is an estimated treatment effect in the original unit (log response time). 

For `c_mean` (from 0 to 5, a 5-unit change) as 
$$d = \frac{-0.0508 \times 5}{\sqrt{0.1803 + 0.3899}} = `r -0.0508 * 5 / sqrt(0.1803 + 0.3899)`$$
For `c_sal` (from 0 to 5, a 5-unit change), the average effect size can be computed as
$$d = \frac{-0.13127 \times 5}{\sqrt{0.1803 + 0.3899}} = `r -0.13127 * 5 / sqrt(0.1803 + 0.3899)`$$
For `oldage` (not a manipulated variable), 
$$d = \frac{0.80607}{\sqrt{0.1803 + 0.3899}} = `r 0.80607 / sqrt(0.1803 + 0.3899)`$$

You can also compute $R^2$

```{r r2-m3_rs}
MuMIn::r.squaredGLMM(m3_rs)
```

```{r r2-m1_rs}
MuMIn::r.squaredGLMM(m1_rs)
```


## Bayesian Analyses

For this example, there were 153 persons and 51 items, so the sample size is sufficient for a frequentist analysis. However, in many psychological experiments, the number of clusters (person or item) is usually small, so a [Bayesian analysis](../week7/) should be more stable and reliable. Below I demonstrate the code for running the same model using `brms` (which uses `rstan`). In addition, one can also use a log-normal model, which is preferred over doing log transformation. 

```{r load-brms}
library(brms)
```


```{r m3_brm_ln, cache=TRUE, include=FALSE, echo=TRUE}
# Recode missing to 60
driving_dat <- driving_dat %>% 
  mutate(rt_sec2 = replace_na(rt_sec, 60),  # rescale by a factor of 10
         censored = as.numeric(is.na(rt_sec)))
# Warning: This takes a long time (10 minutes) to run
m3_brm_ln <- brm(rt_sec2 | cens(censored) ~ c_mean + c_sal + oldage +
                   (c_sal | id) +  
                   (oldage | Item), 
                 # prior = c(prior(lkj(2), class = "cor")),
                 # control = list(adapt_delta = .99, max_treedepth = 15),
                 chains = 2L, cores = 2L, 
                 family = lognormal(),
                 data = driving_dat)
```

### Posterior predictive check

You can check whether data simulated data based on the log-normal model have a similar distribution as the observed data using the `pp_check()` function

```{r pp_check-m3_rs}
pp_check(m3_brm_ln)
```


### Plotting

```{r plot-m3_brm_ln}
conditional_effects(m3_brm_ln, type = "pred", effects = "c_mean")
set.seed(123)
# Randomly sample 9 persons
random_persons <- sample(unique(driving_dat$id), size = 9)
conditional_effects(m3_brm_ln, type = "pred", effects = "c_sal", 
                    re_formula = NULL, 
                    conditions = tibble(id = random_persons)
)
# Randomly sample 9 items
random_items <- sample(unique(driving_dat$Item), size = 9)
conditional_effects(m3_brm_ln, type = "pred", effects = "oldage", 
                    re_formula = NULL, 
                    conditions = tibble(Item = random_items)
)
```

