---
title: "Sample Size Planning for MLM"
subtitle: "PSYC 575"
author: "Mark Lai"
institute: "University of Southern California"
date: "2020/10/31 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

$$\newcommand{\bv}[1]{\boldsymbol{\mathbf{#1}}}$$

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(echo = FALSE, comment = ">#", fig.retina = 3)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```

```{r load-pkg, message=FALSE, echo=FALSE}
library(tidyverse)
library(lme4)
theme_set(theme_bw())
```

# Week Learning Objectives

- Describe the importance of having sufficient sample size for scientific research

- Describe conceptually the steps for sample size planning: precision analysis and power analysis

- Perform power analysis for MLM using the PowerUpR application and the `simr` package

---
class: inverse, middle, center

# Why Sample Size?

---

# Small Sample Size is a Problem Because . . . 

### Misleading and noisy results<sup>1</sup>

- When coupled with statistical significance filter<sup>2 3</sup>

### Noisy estimate of effects/coefficients

### Low power

.footnote[

[1] See [Maxwell (2004)](10.1037/1082-989X.9.2.147)

[2] See the graph on [this blog post](https://statmodeling.stat.columbia.edu/2014/11/17/power-06-looks-like-get-used/)

[3] See also [Vasishth et al. (2018)](https://doi.org/10.1016/j.jml.2018.07.004)

]

---

# Sampling Distribution as a Function of Sample Size

.pull-left[

Assume true effect is $\gamma = 0.10$

Let's say 

- when $N = 20$, $p < .05$ when $\hat \gamma \geq `r round(qnorm(.95, sd = 0.5), 2)`$
- when $N = 200$, $p < .05$ when $\hat \gamma \geq `r round(qnorm(.95, sd = 0.5/ sqrt(10)), 2)`$

]

.pull-right[

```{r, fig.height=3.5, fig.width=4.5, out.width='100%'}
ggplot(tibble(gamma = c(-1, 1)), 
       aes(x = gamma)) + 
  stat_function(aes(col = "N = 20"), 
                fun = dnorm, 
                args = list(mean = 0.10, sd = 0.5)) + 
  stat_function(aes(col = "N = 200"), 
                fun = dnorm, 
                args = list(mean = 0.10, sd = 0.5 / sqrt(10))) + 
  labs(x = expression(gamma), col = "")
```

]

???

Add the 0 line, the 0.1 line, and the cutoff lines

---

class: inverse, center, middle

# Standard Error and Precision Analysis

---

# Sample Size and *SE*/Post. *SD*

In the previous graph, when $N = 20$, the sample estimate is likely to be anywhere between -0.4 and 0.6

$$SE \propto \frac{1}{\sqrt{N}}$$

--

One goal of sample size planning is to 

> Have sufficient sample size to get precise (low *SE*) sample estimates of an effect

---

# A Basic Model

Level-1
$$Y_{ij} = \beta_{0j} + \beta_{1j} X\_\text{cmc}_{ij} + e_{ij}$$
$$e_{ij} \sim N(0, \sigma)$$
Level-2
$$
\begin{aligned}
  \beta_{0j} & = \gamma_{00} + \gamma_{01} W_j + u_{0j}  \\
  \beta_{1j} & = \gamma_{10} + \gamma_{11} W_j + u_{1j}  \\
  \begin{bmatrix}
    u_{0j} \\
    u_{1j}
  \end{bmatrix} & \sim 
  N\left(
    \begin{bmatrix}
      0 \\
      0
    \end{bmatrix}, 
    \begin{bmatrix}
      \tau^2_0 &  \\
      \tau_{01} & \tau^2_{1}
    \end{bmatrix}
  \right)
\end{aligned}
$$

--

- $\gamma_{10}$: $X$ (purely level-1 with ICC = 0)
- $\gamma_{01}$: $W$ (level-2)
- $\gamma_{11}$: $W \times X$ (cross-level interaction)

---

# Analytic Formulas of *SE*

$J$ = Number of clusters; $n$ = Cluster size

- E.g., $J = 100$ schools; $n = 10$ students per school

Assuming $\tau_{01} = 0$

\begin{aligned}
    \mathit{SE}(\gamma_{01}) & = \sqrt{\frac{1}{S^2_W}\left(\frac{\tau^2_0}{J} + \frac{\sigma^2}{Jn}\right)}  \\
    \mathit{SE}(\gamma_{10}) & = \sqrt{\frac{\tau^2_1}{J} + \frac{\sigma^2}{JnS^2_X}}  \\
    \mathit{SE}(\gamma_{11}) & = \sqrt{\frac{1}{S^2_W}\left(\frac{\tau^2_1}{J} + \frac{\sigma^2}{JnS^2_X}\right)}  \\
\end{aligned}

---

# Precision Analysis

Group-based therapy for eating disorder (cluster-randomized trial)

- Intervention at group level 

- 10 participants per group

- Outcome standardized (i.e., *SD* = $\sqrt{\tau^2_0 + \sigma^2} = 1$)
    * $\gamma$ = Cohen's $d$

- ICC = .3 (i.e., $\tau^2_0 = .3$)

--

- Goal: estimate $J$ such that $\mathit{SE}(\gamma_{10}) \leq .1$
    * E.g., if we estimated the sample effect size to be $d = .25$, the 95% CI would be approximately [.05, .45]. 

---

# Calculating $J$

When the predictor is binary (e.g., treatment-control), if half of the groups is in one condition, $S^2_W = 0.25$

- Otherwise, if 30% in one condition, $S^2_W = 0.3 \times 0.7$
- $\tau^2_0 = 0.3$, $\sigma^2 = 0.7$, $n = 10$

```{r, include=FALSE}
segam <- function(j, n = 10) {
  sqrt(((0.3 / j) + 0.7 / j / n) * 4)
}
```


E.g., if $J = 30$
$$\mathit{SE}(\gamma_{01}) = \sqrt{\frac{1}{S^2_W}\left(\frac{\tau^2_0}{J} + \frac{\sigma^2}{Jn}\right)} = \sqrt{\frac{1}{0.25}\left(\frac{0.3}{30} + \frac{0.7}{(30)(10)}\right)} = `r segam(30)`$$

--

Keep trying, and you'll find ...

When $J$ = 148, $\mathit{SE}(\gamma_{01}) = `r segam(148)`$

So you'll need 148 groups (74 treatment, 74 control)

---

class: inverse, middle, center

# Power Analysis

---

.pull-left[

Two-tailed test, $\alpha = .05$

$H_0: \gamma_{01} = 0$

```{r, fig.height=4, fig.width=5.5}
num_clus <- 30
ggplot(tibble(gamma = c(-1, 1)), 
       aes(x = gamma)) + 
  stat_function(aes(col = "J = 30"), 
                fun = function(x) {
                  dt(x / segam(num_clus), df = num_clus - 2)
                }) + 
  geom_vline(xintercept = qt(c(.025, .975), df = num_clus - 2) * 
               segam(num_clus)) + 
  labs(x = expression(gamma), col = "")
```

Critical region: $\hat \gamma_{01} \leq `r round(qt(.025, df = num_clus - 2) * segam(num_clus), 2)`$ or $\hat \gamma_{01} \geq `r round(qt(.975, df = num_clus - 2) * segam(num_clus), 2)`$

]

--

.pull-right[

$H_1: \gamma_{01} = 0.3$

```{r, fig.height=4, fig.width=5.5}
ggplot(tibble(gamma = c(-1, 1)), 
       aes(x = gamma)) + 
  stat_function(aes(col = "J = 30"), 
                fun = function(x) {
                  dt((x - 0.3) / segam(num_clus), df = num_clus - 2)
                }) + 
  geom_vline(xintercept = qt(c(.025, .975), df = num_clus - 2) * 
               segam(num_clus)) + 
  labs(x = expression(gamma), col = "")
```

Power<sup>1</sup> $\approx P(\hat \gamma_{01} \leq `r round(qt(.025, df = num_clus - 2) * segam(num_clus), 2)`) + P(\hat \gamma_{01} \geq `r round(qt(.975, df = num_clus - 2) * segam(num_clus), 2)`) = `r pt(qt(.025, df = num_clus - 2) - 0.3 / segam(num_clus), df = num_clus - 2) + 1 - pt(qt(.975, df = num_clus - 2) - 0.3 / segam(num_clus), df = num_clus - 2)`$

.footnote[

[1] In practice, we need to incorporate the sampling variability of the standard error as well, so this power calculation is only a rough approximation. 

]

]

---

.pull-left[

Two-tailed test, $\alpha = .05$

$H_0: \gamma_{01} = 0$

```{r, fig.height=4, fig.width=5.5}
num_clus <- 148
ggplot(tibble(gamma = c(-1, 1)), 
       aes(x = gamma)) + 
  stat_function(aes(col = "J = 148"), 
                fun = function(x) {
                  dt(x / segam(num_clus), df = num_clus - 2)
                }) + 
  geom_vline(xintercept = qt(c(.025, .975), df = num_clus - 2) * 
               segam(num_clus)) + 
  labs(x = expression(gamma), col = "")
```

Critical region: $\hat \gamma_{01} \leq `r round(qt(.025, df = num_clus - 2) * segam(num_clus), 2)`$ or $\hat \gamma_{01} \geq `r round(qt(.975, df = num_clus - 2) * segam(num_clus), 2)`$

]

--

.pull-right[

$H_1: \gamma_{01} = 0.3$

```{r, fig.height=4, fig.width=5.5}
ggplot(tibble(gamma = c(-1, 1)), 
       aes(x = gamma)) + 
  stat_function(aes(col = "J = 148"), 
                fun = function(x) {
                  dt((x - 0.3) / segam(num_clus), df = num_clus - 2)
                }) + 
  geom_vline(xintercept = qt(c(.025, .975), df = num_clus - 2) * 
               segam(num_clus)) + 
  labs(x = expression(gamma), col = "")
```

Power $\approx P(\hat \gamma_{01} \leq `r round(qt(.025, df = num_clus - 2) * segam(num_clus), 2)`) + P(\hat \gamma_{01} \geq `r round(qt(.975, df = num_clus - 2) * segam(num_clus), 2)`) = `r pt(qt(.025, df = num_clus - 2) - 0.3 / segam(num_clus), df = num_clus - 2) + 1 - pt(qt(.975, df = num_clus - 2) - 0.3 / segam(num_clus), df = num_clus - 2)`$

]

---

# Tools for Power Analysis

1. Stand-alone programs

    * [Optimal Design](http://www.hlmsoft.net/od/)
    * [PinT](https://www.stats.ox.ac.uk/~snijders/multilevel.htm#progPINT)

2. R packages

    * `simr`

3. Spreadsheet/Webapp

    * [PowerUp!](https://www.causalevaluation.org/power-analysis.html)

See more discussion in [Arend & SchÃ¤fer (2019)](https://doi.org/10.1037/met0000195)

---

class: middle, center

# PowerUpR Shiny App

https://powerupr.shinyapps.io/index/

---

# Monte Carlo Simulation for Power Analysis

- Simulate a large number (e.g., $R$ = 1,000) of data sets based on given effect size, ICC, etc

- Fit an MLM to each simulated data

- Power $\approx$ Proportion of times $p < \alpha$

### See sample R code for using `simr`

---

# Additional Notes on Power

- Increasing $J$ usually leads to higher power than increasing $n$

- Balanced designs generally have higher power than unbalanced designs

- Larger sample size required for testing level-2 predictors

- Testing an interaction requires a much larger sample size

    * E.g., 16 times larger than for a main effect

???

Doubling $J$ is better than doubling $n$


