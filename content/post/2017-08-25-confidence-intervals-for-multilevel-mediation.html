---
title: Confidence Intervals for Multilevel Mediation (Draft)
author: Mark Lai
date: '2017-08-25'
slug: confidence-intervals-for-multilevel-mediation
bibliography: references.bib
output:
  blogdown::html_page:
    toc: true
categories:
  - Statistics
tags:
  - R
  - multilevel
  - mediation
  - confidence interval
  - Bayesian
---


<div id="TOC">
<ul>
<li><a href="#quasi-bayesianmonte-carlo-ci-with-the-mediation-package">Quasi-Bayesian/Monte Carlo CI With the <code>mediation</code> Package</a></li>
<li><a href="#analytical-approaches-for-ci-with-the-rmediation-package">Analytical Approaches for CI With the <code>RMediation</code> Package</a><ul>
<li><a href="#distribution-of-product-of-coefficients">Distribution of Product of Coefficients</a></li>
<li><a href="#asymptotic-normal-ci">Asymptotic Normal CI</a></li>
</ul></li>
<li><a href="#case-bootstrap">Case Bootstrap</a><ul>
<li><a href="#bootstrap-ci">Bootstrap CI</a></li>
</ul></li>
<li><a href="#fully-bayesian-approach-with-rstan">Fully Bayesian Approach With <code>rstan</code></a><ul>
<li><a href="#posterior-credible-intervals">Posterior (Credible) Intervals</a></li>
</ul></li>
<li><a href="#summary-table-of-different-cis">Summary Table of Different CIs:</a></li>
<li><a href="#bibliography">Bibliography</a></li>
</ul>
</div>

<p>The data are from the <code>mediation</code> package, which are simulated data with the source of the Education Longitudinal Study of 2002. For the interest of time as well as to consider situations where asymptotic normality may not hold, I only select 50 schools (out of 568) from the sample.</p>
<pre class="r"><code>library(tidyverse)
library(lme4)
library(mediation)
data(&quot;school&quot;, package = &quot;mediation&quot;)
# Select only a random sample of 24 schools, stratified by 
# `coed` and `catholic`
set.seed(827)
# School-level subsample:
school_sub &lt;- school %&gt;% sample_n(size = 50) %&gt;% arrange(SCH_ID)
school_sub %&gt;% as_data_frame()</code></pre>
<pre><code>## # A tibble: 50 x 5
##    SCH_ID  coed smorale  free catholic
##     &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;    &lt;int&gt;
##  1     31     1       4     1        0
##  2     34     1       4     4        0
##  3     51     1       4     4        0
##  4     67     1       3     4        0
##  5     98     1       2     3        0
##  6    104     1       4     2        0
##  7    117     1       3     1        0
##  8    122     1       5     6        0
##  9    130     1       4     4        1
## 10    132     1       5     5        0
## # ... with 40 more rows</code></pre>
<pre class="r"><code># Student-level subsample:
student_sub &lt;- student %&gt;% filter(SCH_ID %in% school_sub$SCH_ID)
student_sub %&gt;% as_data_frame()</code></pre>
<pre><code>## # A tibble: 806 x 13
##    fight attachment  work score  late  coed smorale gender income  free
##    &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;  &lt;int&gt;  &lt;int&gt; &lt;int&gt;
##  1     0          0     0    37     3     1       4      1      7     6
##  2     0          1     0    38     2     1       4      1     10     6
##  3     1          1     0    46     2     1       4      0      8     6
##  4     1          0     1    50     3     1       4      0     10     6
##  5     0          1     1    40     3     1       4      1      6     6
##  6     0          1     0    52     3     1       4      1      8     6
##  7     0          0     1    37     1     1       4      0      9     6
##  8     0          1     0    41     4     1       4      0      7     6
##  9     0          1     1    34     3     1       4      0      8     6
## 10     0          1     1    54     3     1       4      0      7     6
## # ... with 796 more rows, and 3 more variables: pared &lt;int&gt;,
## #   catholic &lt;int&gt;, SCH_ID &lt;int&gt;</code></pre>
<p>The example is taken from <a href="ftp://ftp.gr.vim.org/mirrors/CRAN/web/packages/mediation/vignettes/mediation.pdf">the vignette of the <code>mediation</code> package</a> (p. 19), where a school-level poverty indicator (<code>free</code>, “percent of 10th grade students receiving free lunch” with 7 levels) is hypothesized to cause school-level morale (<code>smorale</code> with 4 levels), which in turn causes student-level tardiness (<code>late</code>, “frequency in which the student was late for school” with 5 levels). For the mediator equation, the school-level covariates are <code>catholic</code> and <code>coed</code>; for the outcome equation, in addition to the school-level covariates, student-level covariates are <code>gender</code>, <code>income</code>, <code>pared</code>.</p>
<div id="quasi-bayesianmonte-carlo-ci-with-the-mediation-package" class="section level2">
<h2>Quasi-Bayesian/Monte Carlo CI With the <code>mediation</code> Package</h2>
<p>The <code>mediate()</code> function provides CI for the indirect effect using Quasi-Bayesian method, which I believe is similar to the Monte Carlo method by assuming normality of the <span class="math inline">\(a\)</span> path and the <span class="math inline">\(b\)</span> path. Bootstrapping is not supported when one equation is a multilevel model.</p>
<pre class="r"><code># Using the mediation package
# 1. Mediator equation
med_fit &lt;- lm(smorale ~ free + catholic + coed, data = school_sub)
# 2. Outcome equation
out_fit &lt;- lmer(late ~ free + smorale + catholic + coed +
                  gender + income + pared + (1 | SCH_ID), data = student_sub)
# Record the time:
system.time(med_out &lt;- mediate(med_fit, out_fit, treat = &quot;free&quot;, 
                               mediator = &quot;smorale&quot;,
                               control.value = 3, treat.value = 4, sims = 500))</code></pre>
<pre><code>##    user  system elapsed 
##   12.44    0.05   12.53</code></pre>
<pre class="r"><code>summary(med_out)  # Summary of mediation analysis</code></pre>
<pre><code>## 
## Causal Mediation Analysis 
## 
## Quasi-Bayesian Confidence Intervals
## 
## Mediator Groups: 
## 
## Outcome Groups: SCH_ID 
## 
## Output Based on Overall Averages Across Groups 
## 
##                Estimate 95% CI Lower 95% CI Upper p-value
## ACME            0.00779     -0.00720         0.03    0.34
## ADE             0.01799     -0.03989         0.07    0.53
## Total Effect    0.02578     -0.03279         0.08    0.39
## Prop. Mediated  0.14422     -3.00260         3.39    0.52
## 
## Sample Size Used: 806 
## 
## 
## Simulations: 500</code></pre>
<p>The output gives the “ACME” (average causal mediation effect) estimate, which equals estimator of <span class="math inline">\(ab\)</span> under a normal model, as well as “ADE” (average direct effect), which equals estimator of <span class="math inline">\(c&#39;\)</span> under a normal model, and ACME and ADE add up to the “Total Effect”, and the proportion mediated as estimating <span class="math inline">\(ab / (ab + c&#39;)\)</span>. The posterior median was used for all the quantities, together with the credible intervals.</p>
<p>One can use the posterior samples (e.g., <code>d0.sim</code> for the posterior samples of the <span class="math inline">\(a\)</span> path) to compute any derived quantities. However, the posterior samples for the variance components are not available, so one cannot compute standardized coefficients or effect sizes defined using variance components.</p>
</div>
<div id="analytical-approaches-for-ci-with-the-rmediation-package" class="section level2">
<h2>Analytical Approaches for CI With the <code>RMediation</code> Package</h2>
<p>The two main analytical approaches are <span class="citation">(see MacKinnon, Lockwood, and Williams 2004)</span>:</p>
<ol style="list-style-type: decimal">
<li>distribution of product of coefficients</li>
<li>Asymptotic normal CI (or Wald CI)</li>
</ol>
<div id="distribution-of-product-of-coefficients" class="section level3">
<h3>Distribution of Product of Coefficients</h3>
<p>This approach uses the quantiles of the distribution of <span class="math inline">\(ab\)</span> when <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are assumed bivariate normal. Therefore, the Quasi-Bayesian/Monte Carlo approach can be viewed as an approximation of it. It is, however, less flexible as it does not provide distributions of other derived quantities (e.g., proportion mediated).</p>
<pre class="r"><code># With RMediation
nmtx &lt;- &quot;free&quot;  # name of treatment variable
nmmed &lt;- &quot;smorale&quot;  # name of mediator
a &lt;- coef(med_fit)[nmtx]  # estimate of a path with name removed
va &lt;- vcov(med_fit)[nmtx, nmtx]  # sampling variance of a path
b &lt;- fixef(out_fit)[nmmed]  # estimate of b path with name removed
vb &lt;- vcov(out_fit)[nmmed, nmmed]  # sampling variance of b path
# Distribution of Product of Coefficients
(med_dop &lt;- RMediation::medci(mu.x = a, mu.y = b, type = &quot;dop&quot;, 
                              se.x = sqrt(va), se.y = sqrt(vb)))</code></pre>
<pre><code>## $`97.5% CI`
## [1] -0.007804832  0.030636061
## 
## $Estimate
##        free 
## 0.007047165 
## 
## $SE
##        free 
## 0.009644314</code></pre>
</div>
<div id="asymptotic-normal-ci" class="section level3">
<h3>Asymptotic Normal CI</h3>
<p>The asymptotic <em>SE</em> for the product of two normal variables, as defined in the <code>RMediation</code> package, is: <span class="math display">\[{\textit{SE}}(\hat a \hat b) = \sqrt{a^2 {\textit{SE}}^2(b) + b^2 {\textit{SE}}^2(a) + 
                       2 ab {\textit{SE}}(a) {\textit{SE}}(b) r_{\hat a \hat b} + 
                       {\textit{SE}}^2(a) {\textit{SE}}^2(b) r_{\hat a \hat b}}\]</span> And we replace <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\({\textit{SE}}(a)\)</span>, <span class="math inline">\({\textit{SE}}(b)\)</span> with the corresponding sample estimates. Note that as we use separate equations to obtain <span class="math inline">\(\hat a\)</span> and <span class="math inline">\(\hat b\)</span>, the correlation between them, <span class="math inline">\(r_{\hat a \hat b}\)</span>, is assumed zero, so the asymptotic <em>SE</em> is computed as: <span class="math display">\[{\textit{SE}}(\hat a \hat b) = \sqrt{a^2 {\textit{SE}}^2(b) + b^2 {\textit{SE}}^2(a)}\]</span> and the Asymptotic symmetric CI is <span class="math inline">\(\hat a \hat b \pm 1.96 {\textit{SE}}(\hat a \hat b)\)</span>.</p>
<pre class="r"><code># Assuming Asymptotic Normality
(med_asym &lt;- RMediation::medci(mu.x = a, mu.y = b, type = &quot;asymp&quot;, 
                               se.x = sqrt(va), se.y = sqrt(vb)))</code></pre>
<pre><code>## $`97.5% CI`
## [1] -0.01185534  0.02594967
## 
## $Estimate
##        free 
## 0.007047165 
## 
## $SE
##        free 
## 0.009644314</code></pre>
</div>
</div>
<div id="case-bootstrap" class="section level2">
<h2>Case Bootstrap</h2>
<p>All the above approaches involve normality assumptions: the quasi-Bayesian and the distribution of product approaches assume the sampling distribution of <span class="math inline">\(\hat a\)</span> and <span class="math inline">\(\hat b\)</span> are jointly normal, whereas the asymptotic CI assumes that the sampling distribution of <span class="math inline">\(\hat a \hat b\)</span> is normal. In small sample and/or with non-normal data, such assumptions may not hold. That is one of the reasons that resampling methods, in particular the bootstrap, is popular for single-level mediation analysis.</p>
<p>There are many methods to do bootstrapping with multilevel analysis <span class="citation">(see Leeden, Meijer, and Busing 2008 for an overview)</span>. However, to my knowledge most of them are not directly built in multilevel software, especially for mediation models. A relatively simple bootstrapping method is the <em>case bootstrap</em>, which resample intact clusters with replacement. The advantage is that it basically makes no assumption about the data, such as the specification of the functional form and the distribution of the random effects. Therefore the results should be robust. The drawback, however, is that when the cluster sizes are not balanced, as in our example, it results in bootstrap samples with different level-1 sample sizes. And based on my experience it is generally less efficient and requires a relatively large number of clusters to perform well. Below is my implementation of the case bootstrap for this example, which include the indirect effect and some derived quantities.</p>
<pre class="r"><code>library(boot)  # load the boot package
# Get the unique school IDs as a global variable
sch_id &lt;- school_sub$SCH_ID

lv1_resample &lt;- function(new_lv2_id, data = student_sub, 
                         group_var = &quot;SCH_ID&quot;) {
  # Return a resampled lv-1 data set given an input of cluster values
  # 
  # Args:
  #   new_lv2_id: A vector (character/numeric) showing the cluster values 
  #               to be selected. 
  #   data: The lv-1 data set to be resampled. 
  #   group_var: A character vector of length 1 indicating the variable name
  #              for cluster ID
  # Returns:
  #   A data.frame object with the resampled data. 
  group &lt;- data[[group_var]]
  N &lt;- nrow(data)
  new_lv1_index &lt;- unlist(
    lapply(new_lv2_id, function(i) seq_len(N)[group == i]))
  gp_tab &lt;- table(group, dnn = NULL)
  gp_length &lt;- gp_tab[as.character(new_lv2_id)]
  # `new_group` make sure that each resampled cluster get a distinct 
  # cluster ID. 
  new_group &lt;- rep(seq_along(new_lv2_id), gp_length)
  new_data &lt;- data[new_lv1_index, , drop = FALSE]
  new_data[group_var] &lt;- new_group
  rownames(new_data) &lt;- NULL
  new_data
}

ab_resample &lt;- function(data_lv2, i, ...) {
  new_sch_id &lt;- sch_id[i]
  med_fit &lt;- lm(smorale ~ free + catholic + coed, data = data_lv2[i, ])
  new_stud_dat &lt;- lv1_resample(new_sch_id, ...)
  # Use `calc.dervis` to skip computing the derivatives and save 
  # some time for each bootstrap replication
  out_fit &lt;- lmer(late ~ free + smorale + catholic + coed +
                  gender + income + pared + (1 | SCH_ID), data = new_stud_dat, 
                  control = lmerControl(calc.derivs = FALSE))
  a &lt;- unname(coef(med_fit)[nmtx])
  b &lt;- unname(fixef(out_fit)[nmmed])
  ab &lt;- a * b
  va &lt;- vcov(med_fit)[nmtx, nmtx]
  vb &lt;- vcov(out_fit)[nmmed, nmmed]
  # variance components (for standardizing y):
  sigma_y &lt;- sigma(out_fit)  # level-1 SD
  tau &lt;- getME(out_fit, &quot;theta&quot;) * sigma_y  # random intercept SD
  # c-prime (for getting proportion mediated)
  c_prime &lt;- unname(fixef(out_fit)[nmtx])
  c(ab = ab, 
    vab = a^2 * vb + b^2 * va, 
    ab_stdy = ab / sqrt(tau^2 + sigma_y^2), 
    pm = ab / (ab + c_prime))
}</code></pre>
<pre class="r"><code>system.time(med_boo &lt;- boot(school_sub, ab_resample, 1000))</code></pre>
<pre><code>##    user  system elapsed 
##  826.31    0.15  829.97</code></pre>
<pre class="r"><code>med_boo</code></pre>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = school_sub, statistic = ab_resample, R = 1000)
## 
## 
## Bootstrap Statistics :
##         original        bias     std. error
## t1* 7.047165e-03 -4.332177e-04 1.060356e-02
## t2* 7.042008e-05  4.327382e-05 9.964896e-05
## t3* 6.224259e-03 -3.430022e-04 9.401763e-03
## t4* 2.760381e-01  6.292969e-01 1.827176e+01</code></pre>
<p>We can plot the bootstrap distributions (Note the non-normality)</p>
<pre class="r"><code>plot(med_boo, index = 1L)</code></pre>
<p><img src="/post/2017-08-25-confidence-intervals-for-multilevel-mediation_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The output shows that the indirect effect estimate was biased by -6.1%, whereas the estimated sampling variance was biased by 61%! (or 16% for standard error bias)</p>
<div id="bootstrap-ci" class="section level3">
<h3>Bootstrap CI</h3>
<div id="indirect-effect" class="section level4">
<h4>Indirect effect</h4>
<p>Generally BCa (bias-corrected and accelerated) and studentized CIs (also called bootstrap-<span class="math inline">\(t\)</span>) are more accurate <span class="citation">(see Davison and Hinkley 1997, <span class="citation">Leeden, Meijer, and Busing (2008)</span>, <span class="citation">G. W. Cheung and Lau (2008)</span>)</span>. However, the BCa needs the accerlation value (which is used to correct for skewness), which is estimated using the regression estimation here, and to my knowledge its use for multilevel data has not been tested.</p>
<p>The studentized CI requires the use of the sampling variance of the statistic to be bootstrapped, which is why I also computed the asymptotic variance of the indirect effect in each bootstrap replication.</p>
<pre class="r"><code># For (unstandardized) indirect effect
(med_bootci &lt;- boot.ci(med_boo, type = &quot;all&quot;, index = 1:2))</code></pre>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = med_boo, type = &quot;all&quot;, index = 1:2)
## 
## Intervals : 
## Level      Normal              Basic             Studentized     
## 95%   (-0.0133,  0.0283 )   (-0.0178,  0.0244 )   (-0.0049,  0.0400 )  
## 
## Level     Percentile            BCa          
## 95%   (-0.0103,  0.0319 )   (-0.0061,  0.0444 )  
## Calculations and Intervals on Original Scale
## Some BCa intervals may be unstable</code></pre>
<p>As you can see, for the indirect effect estimate, both BCa and studentized CIs gave results that are closer compared to other types of CIs. The BCa was known to sometimes overcorrect for skewness, and in this case it might seem to be pushing the confidence limits to the right.</p>
</div>
<div id="y-standardized-indirect-effect" class="section level4">
<h4><span class="math inline">\(y\)</span>-standardized indirect effect</h4>
<p>We also can get study the the indirect effect with <span class="math inline">\(y\)</span> standardized, referred to as <span class="math inline">\(ab_{ps}\)</span> in the literature, defined as <span class="math display">\[ab_{ps} = \frac{ab}{\sqrt{\tau^2_y + \sigma^2_y}},\]</span> where <span class="math inline">\(\tau^2_y + \sigma^2_y\)</span> is the total variance of <span class="math inline">\(y\)</span>. <span class="math inline">\(ab_{ps}\)</span> has the interpretation of:</p>
<blockquote>
<p>Every unit increase in <span class="math inline">\(x\)</span> (treatment variable) results in a change of <span class="math inline">\(ab_{ps}\)</span> standard deviations in <span class="math inline">\(y\)</span> through the mediator.</p>
</blockquote>
<p>First look at the bootstrap distribution:</p>
<pre class="r"><code>plot(med_boo, index = 3L)</code></pre>
<p><img src="/post/2017-08-25-confidence-intervals-for-multilevel-mediation_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>It’s easy to get the bootstrap CIs. However, for the <span class="math inline">\(y\)</span>-standardized indirect effect and the proportion mediated it would be more work to obtain the sampling variance estimates (which can be obtained with the delta method or with other resampling method within each bootstrap sample; the former needs some derivation and may not be very accurate and the latter will increase the computation time by a factor of 100 or more, which is not practical), so I did not request for the studentized CI.</p>
<pre class="r"><code># For y-standardized indirect
boot.ci(med_boo, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;, &quot;bca&quot;), index = 3L)</code></pre>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = med_boo, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;, 
##     &quot;bca&quot;), index = 3)
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   (-0.0119,  0.0250 )   (-0.0154,  0.0214 )  
## 
## Level     Percentile            BCa          
## 95%   (-0.0089,  0.0279 )   (-0.0057,  0.0399 )  
## Calculations and Intervals on Original Scale
## Some BCa intervals may be unstable</code></pre>
<p>As shown in the result, BCa interval is wider but with higher lower and upper confidence limits. For single-level mediation <span class="citation">M. W.-L. Cheung (2009)</span> showed that the percentile and BCa CIs are better than Wald CI and using the <code>PRODCLIN CI</code> macro. It is still an open question how the different bootstrap CIs perform in multilevel mediation.</p>
</div>
<div id="proportion-mediated" class="section level4">
<h4>Proportion mediated</h4>
<p>Again, check the bootstrap distribution:</p>
<pre class="r"><code>plot(med_boo, index = 4L)</code></pre>
<p><img src="/post/2017-08-25-confidence-intervals-for-multilevel-mediation_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Finally, we can get CIs for proportion mediated:</p>
<pre class="r"><code># For proportion mediated
boot.ci(med_boo, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;, &quot;bca&quot;), index = 4L)</code></pre>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = med_boo, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;, 
##     &quot;bca&quot;), index = 4)
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   (-36.1652,  35.4587 )   ( -1.9291,   2.1622 )  
## 
## Level     Percentile            BCa          
## 95%   ( -1.6101,   2.4812 )   ( -0.0772, 485.1805 )  
## Calculations and Intervals on Original Scale
## Some BCa intervals may be unstable</code></pre>
<p>The percentile CI (and to a less degree the basic CI) was close to the one given with the <code>mediation</code> package, whereas the normal bootstrap CI and the BCa CI had much wider intervals. After all, I don’t think proportion mediated would be a good measure of effect size, as also pointed out in <span class="citation">Miočević et al. (2017)</span>.</p>
<p>Note that I only illustrated case bootstrap in this post. For clustered data, in <span class="citation">Davison and Hinkley (1997)</span>, it was found that residual bootstrap may result in better coverage. I may implement residual bootstrap for mediation in the R package I am working on, <code>bootmlm</code>.</p>
</div>
</div>
</div>
<div id="fully-bayesian-approach-with-rstan" class="section level2">
<h2>Fully Bayesian Approach With <code>rstan</code></h2>
<p>Brad Efron said the bootstrap can be an approximation of Bayesian estimation. So we can actually do a fully Bayesian model, which actually is not complicated to fit. It is basically putting a Bayesian multiple regression and a random intercept model together. Given that the scales of the variables are quite similar and generally with SD = 0.5 to 2, I used weakly informative priors with <span class="math inline">\(N(0, 10^2)\)</span> for the fixed effects and <span class="math inline">\(t_3(0, 10^2)\)</span> for the random effect standard deviations (i.e., <span class="math inline">\(\sigma_m\)</span>, <span class="math inline">\(\tau_y\)</span>, <span class="math inline">\(\sigma_y\)</span>).</p>
<p>The Bayesian model here assumes normality in the random effects but not asymptotic normality of the posterior distributions of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> and other parameters.</p>
<pre class="r"><code>library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = 2L)
library(coda)</code></pre>
<p>Below is the STAN code for the multilevel mediation model:</p>
<pre><code>data { 
  // input for mediator model
  int&lt;lower=1&gt; J;  // total number of clusters
  vector[J] M;  // mediator variable (at level-2)
  int&lt;lower=1&gt; Kw;  // number of effects for the mediator (including intercept)
  matrix[J, Kw] W;  // level-2 design matrix for the mediator (including intercept)
  // input for outcome model
  int&lt;lower=1&gt; N;  // total number of observations 
  vector[N] Y;  // mediator variable (at level-2)
  int&lt;lower=1&gt; Kx;  // number of effects for the outcome (including intercept)
  matrix[N, Kx] X;  // level-1 design matrix for the outcome (including intercept)
  int&lt;lower=1&gt; gid[N];  // cluster ID
} 
transformed data { 
  int Kwc = Kw - 1; 
  int Kxc = Kx - 1; 
  matrix[J, Kwc] Wc;  // centered version of W 
  matrix[N, Kxc] Xc;  // centered version of X 
  for (i in 2:Kw) { 
    Wc[, i - 1] = W[, i] - mean(W[, i]); 
  } 
  for (i in 2:Kx) { 
    Xc[, i - 1] = X[, i] - mean(X[, i]); 
  } 
} 
parameters { 
  vector[Kwc] a;  // fixed effects for M
  vector[Kxc] b;  // fixed effects for Y
  real temp_b0_m;  // intercept for M (with centered predictors)
  real temp_b0_y;  // intercept for Y (with centered predictors)
  real&lt;lower=0&gt; sigma_m;  // residual SD for M
  real&lt;lower=0&gt; tau_y;  // group-level residual SD for Y
  real&lt;lower=0&gt; sigma_y;  // group-level residual SD for Y
  vector[J] z_y;  // unscaled group-level effects 
} 
transformed parameters { 
  // group-level effects 
  vector[J] beta_y = tau_y * z_y; 
} 
model { 
  vector[J] mu_m = temp_b0_m + Wc * a;
  vector[N] mu_y = temp_b0_y + Xc * b; 
  for (n in 1:N) { 
    mu_y[n] = mu_y[n] + beta_y[gid[n]];  // group specific effect
  } 
  // prior specifications 
  a ~ normal(0, 10);
  b ~ normal(0, 10); 
  sigma_m ~ student_t(3, 0, 10); 
  sigma_y ~ student_t(3, 0, 10); 
  tau_y ~ student_t(3, 0, 10); 
  z_y ~ normal(0, 1); 
  // likelihood contribution 
  M ~ normal(mu_m, sigma_m);
  Y ~ normal(mu_y, sigma_y); 
} 
generated quantities {
  real ab = a[1] * b[2];  // indirect effect
  real ab_stdy = ab / sqrt(tau_y^2 + sigma_y^2); 
  real pm = ab / (ab + b[2]);  // proportion mediated
}</code></pre>
<pre class="r"><code>numeric_id &lt;- function(id) {
  # Make group ID to be natural numbers from 1, 2, ..., as needed in the 
  # STAN program
  match(id, unique(id))
}
med_sdata &lt;- list(J = nrow(school_sub), 
                  M = school_sub$smorale, 
                  Kw = 4, 
                  W = cbind(1, school_sub[c(&quot;free&quot;, &quot;catholic&quot;, &quot;coed&quot;)]), 
                  N = nrow(student_sub), 
                  Y = student_sub$late, 
                  Kx = 8, 
                  X = cbind(1, student_sub[c(&quot;free&quot;, &quot;smorale&quot;, &quot;catholic&quot;, 
                                             &quot;coed&quot;, &quot;gender&quot;, &quot;income&quot;, 
                                             &quot;pared&quot;)]), 
                  gid = numeric_id(student_sub$SCH_ID))
med_stan &lt;- stan(&quot;stan_mlm_mediate.stan&quot;, data = med_sdata, 
                 pars = c(&quot;temp_b0_m&quot;, &quot;temp_b0_y&quot;, &quot;a&quot;, &quot;b&quot;, 
                          &quot;sigma_m&quot;, &quot;sigma_y&quot;, &quot;tau_y&quot;, 
                          &quot;ab&quot;, &quot;ab_stdy&quot;, &quot;pm&quot;))</code></pre>
<div id="posterior-credible-intervals" class="section level3">
<h3>Posterior (Credible) Intervals</h3>
<p>We can get the commonly-used equal-tailed interval or the shorter (but maybe less stable) highest posterior density interval (HPDI).</p>
<pre class="r"><code># Extract the posterior samples
pars_post &lt;- as.matrix(med_stan, pars = c(&quot;ab&quot;, &quot;ab_stdy&quot;, &quot;pm&quot;))
# Posterior distribution of ab:
hist(pars_post[ , 1], xlab = &quot;ab&quot;, main = &quot;Posterior distribution of ab&quot;)</code></pre>
<p><img src="/post/2017-08-25-confidence-intervals-for-multilevel-mediation_files/figure-html/unnamed-chunk-16-1.png" width="50%" /></p>
<pre class="r"><code># Equal-tailed interval:
(post_ci &lt;- apply(pars_post, 2, quantile, probs = c(.025, .975)))</code></pre>
<pre><code>##        parameters
##                   ab     ab_stdy         pm
##   2.5%  -0.008760216 -0.00761549 -0.2975376
##   97.5%  0.031320613  0.02757498  0.0376768</code></pre>
<pre class="r"><code># HPDI
(post_hpdi &lt;- coda::HPDinterval(as.mcmc(pars_post)))</code></pre>
<pre><code>##                lower      upper
## ab      -0.010734393 0.02922747
## ab_stdy -0.009220888 0.02598859
## pm      -0.282189649 0.04457961
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
</div>
</div>
<div id="summary-table-of-different-cis" class="section level2">
<h2>Summary Table of Different CIs:</h2>
<pre class="r"><code>format_ci &lt;- function(ci) {
  paste0(&quot;(&quot;, paste(comma(ci), collapse = &quot;,&quot;), &quot;)&quot;)
}
data_frame(Method = c(&quot;Quasi-Bayesian&quot;, &quot;DOP&quot;, &quot;Asymptotic&quot;, 
                      &quot;Boot Studentized&quot;, &quot;Boot Percentile&quot;, 
                      &quot;Boot BCa&quot;, &quot;Bayesian CI&quot;, &quot;Bayesian HPDI&quot;), 
           `95% CI` = c(format_ci(med_out$d0.ci), 
                        format_ci(med_dop[[1]]), 
                        format_ci(med_asym[[1]]), 
                        format_ci(tail(med_bootci$student[1, ], 2L)), 
                        format_ci(tail(med_bootci$percent[1, ], 2L)), 
                        format_ci(tail(med_bootci$bca[1, ], 2L)), 
                        format_ci(post_ci[ , &quot;ab&quot;]), 
                        format_ci(post_hpdi[&quot;ab&quot;, ]))) %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="left">95% CI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Quasi-Bayesian</td>
<td align="left">(-0.0072, 0.0316)</td>
</tr>
<tr class="even">
<td align="left">DOP</td>
<td align="left">(-0.0078, 0.0306)</td>
</tr>
<tr class="odd">
<td align="left">Asymptotic</td>
<td align="left">(-0.012, 0.026)</td>
</tr>
<tr class="even">
<td align="left">Boot Studentized</td>
<td align="left">(-0.0049, 0.0400)</td>
</tr>
<tr class="odd">
<td align="left">Boot Percentile</td>
<td align="left">(-0.010, 0.032)</td>
</tr>
<tr class="even">
<td align="left">Boot BCa</td>
<td align="left">(-0.0061, 0.0444)</td>
</tr>
<tr class="odd">
<td align="left">Bayesian CI</td>
<td align="left">(-0.0088, 0.0313)</td>
</tr>
<tr class="even">
<td align="left">Bayesian HPDI</td>
<td align="left">(-0.011, 0.029)</td>
</tr>
</tbody>
</table>
<p>The CIs across methods are somewhat similar, with the exception of BCa and studentized bootstrap CIs and the asymptotic CI, with the two bootstrap CIs having wider intervals. Further studies are needed to compare their performance.</p>
</div>
<div id="bibliography" class="section level2 unnumbered">
<h2>Bibliography</h2>
<div id="refs" class="references">
<div id="ref-Cheung2008">
<p>Cheung, Gordon W., and Rebecca S. Lau. 2008. “Testing mediation and suppression effects of latent variables.” <em>Organizational Research Methods</em> 11 (2): 296–325. doi:<a href="https://doi.org/10.1177/1094428107300343">10.1177/1094428107300343</a>.</p>
</div>
<div id="ref-Cheung2009">
<p>Cheung, Mike W-L. 2009. “Comparison of methods for constructing confidence intervals of standardized indirect effects.” <em>Behavior Research Methods</em> 41 (2): 425–38. doi:<a href="https://doi.org/10.3758/BRM.41.2.425">10.3758/BRM.41.2.425</a>.</p>
</div>
<div id="ref-Davison1997">
<p>Davison, A. C., and D. V. Hinkley. 1997. <em>Bootstrap methods and their application</em>. Cambridge, UK: Cambridge University Press.</p>
</div>
<div id="ref-VanderLeeden2008">
<p>Leeden, Rien van der, Erik Meijer, and Frank M. T. A. Busing. 2008. “Resampling multilevel models.” In <em>Handbook of Multilevel Analysis</em>, edited by Jan de Leeuw and Erik Meijer, 401–33. New York, NY: Springer.</p>
</div>
<div id="ref-MacKinnon2004">
<p>MacKinnon, David P., Chondra M. Lockwood, and Jason Williams. 2004. “Confidence limits for the indirect effect: Distribution of the product and resampling Methods.” <em>Multivariate Behavioral Research</em> 39: 99–128. doi:<a href="https://doi.org/10.1207/s15327906mbr3901_4">10.1207/s15327906mbr3901_4</a>.</p>
</div>
<div id="ref-Miocevic2017">
<p>Miočević, Milica, Holly P. O’Rourke, David P. MacKinnon, and Hendricks C Brown. 2017. “Statistical properties of four effect-size measures for mediation models.” <em>Behavior Research Methods</em>, March. doi:<a href="https://doi.org/10.3758/s13428-017-0870-1">10.3758/s13428-017-0870-1</a>.</p>
</div>
</div>
</div>
